---
name: parser
packages:
- logstash
- logsearch-config
- java8
templates:
  bin/parser_ctl: bin/parser_ctl
  bin/monit_debugger: bin/monit_debugger
  data/properties.sh.erb: data/properties.sh
  helpers/ctl_setup.sh: helpers/ctl_setup.sh
  helpers/ctl_utils.sh: helpers/ctl_utils.sh
  config/input_and_output.conf.erb: config/input_and_output.conf
  config/filters_pre.conf.erb: config/filters_pre.conf
  config/filters_post.conf.erb: config/filters_post.conf
  config/filters_override.conf.erb: config/filters_override.conf
  config/log4j2.properties.erb: config/log4j2.properties
  logsearch/logs.yml: logsearch/logs.yml
properties:
  logstash.metadata_level:
    description: "Whether to include additional metadata throughout the event lifecycle. NONE = disabled, DEBUG = fully enabled"
    default: "NONE"
  logstash.log_level:
    description: The default logging level (e.g. WARN, DEBUG, INFO)
    default: info

  logstash_parser.debug:
    description: Debug level logging
    default: false
  logstash.heap_size:
    description: sets jvm heap sized
  logstash_parser.message_max_size:
    description: "Maximum log message length.  Anything larger is truncated (TODO: move this to ingestor?)"
    default: 1048576
  logstash_parser.filters:
    description: "The configuration to embed into the logstash filters section. Can either be a set of parsing rules as a string or a list of hashes in the form of [{name: path_to_parsing_rules.conf}]"
    default: ''
  logstash_parser.deployment_dictionary:
    description: "A list of files concatenated into one deployment dictionary file. Each file contains a hash of job name-deployment name keypairs for @source.deployment lookup."
    default: [ "/var/vcap/packages/logsearch-config/deployment_lookup.yml" ]
  logstash_parser.inputs:
    description: |
      A list of input plugins, with a hash of options for each of them. Please refer to example below.
    example:
      inputs:
        - plugin: rabbitmq
          options:
            host: 192.168.1.1
            user: logsearch
            password: c1oudbunny
    default: [ { plugin: "redis", options : {} } ]
  logstash_parser.outputs:
    description: |
      A list of output plugins, with a hash of options for each of them. Please refer to example below.
    example:
      inputs:
        - plugin: mongodb
          options:
            uri: 192.168.1.1
            database: logsearch
            collection: logs                      
    default: [ { plugin: "elasticsearch", options: {} } ]
  logstash_parser.workers:
    description: "The number of worker threads that logstash should use (default: auto = one per CPU)"
    default: auto
  logstash_parser.elasticsearch.idle_flush_time:
    description: "How frequently to flush events if the output queue is not full." 
  logstash_parser.elasticsearch.document_id:
    description: "Use a specific, dynamic ID rather than an auto-generated identifier."
    default: ~
  logstash_parser.elasticsearch.index:
    description: "The specific, dynamic index name to write events to."
    default: "logstash-%{+YYYY.MM.dd}"
  logstash_parser.elasticsearch.index_type:
    description: "The specific, dynamic index type name to write events to."
    default: "%{@type}"
  logstash_parser.elasticsearch.routing:
    description: "The routing to be used when indexing a document."
  logstash_parser.elasticsearch.data_hosts:
    description: The list of elasticsearch data node IPs
    default: [127.0.0.1]
  logstash_parser.elasticsearch.flush_size:
    description: Controls how many logs will be buffered and sent to Elasticsearch for bulk indexing
    default: 500  
  logstash_parser.timecop.reject_greater_than_hours:
    description: "Logs with timestamps greater than this many hours in the future won't be parsed and will get tagged with fail/timecop"
    default: 1
  logstash_parser.timecop.reject_less_than_hours:
    description: "Logs with timestamps less than this many hours in the past won't be parsed and will get tagged with fail/timecop"
    default: 24
  logstash_parser.enable_json_filter:
    description: "Toggles the if_it_looks_like_json.conf filter rule"
    default: false
  logstash_parser.wait_for_templates:
    description: "A list of index templates that need to be present in ElasticSearch before the process starts"
    default: ["index_template"]

  redis.host:
    description: Redis host of queue
  redis.port:
    description: Redis port of queue
    default: 6379
  redis.key:
    description: Name of queue to pull messages from
    default: logstash
